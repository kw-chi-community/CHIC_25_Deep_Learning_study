# 최서영

<details>
<summary>1장</summary>
    - 머신러닝 방식
        
        [사진으로 대체]
        
        [사진으로 대체]
        
    - 대표적인 머신러닝 애플리케이션
        - CNN : 제품 이미지를 보고 자동으로 분류
        - NLP : 자동으로 뉴스 기사를 분류하기
        - 회기 : 내년도 회사의 수익을 예측하기
        - RNN, CNN, 트랜스포머 : 음성을 듣고 이해하는 앱을 만들기
        - 군집 : 구매 이력을 기반으로 고객을 나누기
    - 머신러닝 시스템의 종류
        - 훈련 감동 방법 : 지도학습, 비지도 학습, 준지도 학습, 강화 학습
            - 지도 학습 : 정답이 있는 경우 
            → 선형 회기, 로지스틱 회귀, 서포트 벡터 머신, 결정 트리와 앙상블, 신경망
                
                [사진으로 대체]
                
            - 비지도 학습 : 정답이 없는 경우
            → k-평균, DBSCAN, PCA, 가우시안 혼합, 오토인코더
                
                [사진으로 대체]
                
            - 준지도 학습 : 정답이 일부만 있는 경우
                
                [사진으로 대체]
                
            - 강화 학습 : 행동의 보상이 있는 경우
                
                [사진으로 대체]
                
        - 훈련 시점 : 온라인 학습과 배치 학습
            - 온라인 학습 : 적은 데이터를 사용해 점진적으로 훈련, 실시간 시스템이나 메모리가 부족한 경우 사용
            - 배치 학습 : 전체 데이터를 사용해 오프라인에서 훈련, 컴퓨팅 자원이 풍부한 경우에 사용
        - 모델 생성 : 사례 기반 학습과 모델 기반 학습
            - 사례 기반 학습 : 샘플을 기억하는 것이 훈련, 예측을 위해 샘플 사이의 유사도 측정
                
                [사진으로 대체]
                
            - 모델 기반 학습 : 샘플을 사용해 모델을 훈련, 훈련된 모델을 사용해 예측
                
                [사진으로 대체]
                
    - 주요 도전 과제
        - 충분하지 않은 양의 훈련 데이터
            - 간단한 문제라도 수천 개의 데이터가 필요
            - 이미지나 음성 인식 같은 문제는 수백만 개가 필요할 수 있음
        - 대표성 없는 훈련 데이터
            - 샘플링 잡음 : 우연에 의해 대표성이 없는 데이터
            - 샘플링 편향 : 표본 추출 방법이 잘못된 대표성이 없는 데이터
        - 낮은 품질의 데이터
            - 이상치 샘플 → 고치거나 무시
            - 특성이 누락
                - 해당 특성을 제외
                - 해당 샘플을 제외
                - 누락된 값을 채움
                - 해당 특성을 넣은 경우와 뺀 경우 각기 모델을 훈련
        - 관련 없는 특성
            - 특성 공학은 풀려는 문제에 관련이 높은 특성을 찾는다
                - 특성 선택 : 준비되어 있는 특성 중 가장 유용한 특성 찾기
                - 특성 추출 : 특성을 조합하여 새로운 특성 만듦
        - 과대 적합
            - 훈련 세트에 너무 잘 맞아 일반화 성능이 낮은 현상
            - 규제 이용 → 과대적합 감소
        - 과소 적합
            - 모델이 너무 단순해서 훈련 세트를 잘 학습 못함
            - 해결 방법
                - 모델 파라미터가 더 많은 모델 사용
                - 특성 공학으로 더 좋은 특성 찾음
                - 규제의 강도를 줄임
        - 테스트 세트와 검증 세트
            - 모델의 일반화 성능을 측정 → 훈련 세트와 테스트 세트로 나눔
                - 훈련 세트 → 모델을 훈련하고 테스트 세트로 모델의 일반화 성능을 측정
                    - 하이퍼파라미터 : 알고리즘을 조절하기 위해 사전에 정의하는 파라미터
                - 테스트 세트 → 여러 모델을 평가하면 테스트 세트에 과대적합됩니다
            - 모델 선택 → 훈련 세트, 검증 세트(개발 세트), 테스트 세트로 나눔
        - 훈련-개발 세트
            - 대량의 데이터를 얻기 위해 실전과 다른 데이터로 훈련 세트를 만들 때 → 검증 세트 점수가 과대적합과 데이터 불일치 중 어떤 것인지 모름
            
            → 훈련-개발 세트를 만들어서 훈련한 모델을 평가
            
            - 훈련-개발 세트 성능이 낮으면 → 과대적합
            - 검증 세트 성능이 낮으면 → 데이터 불일치

</details>

<details>
<summary>2장</summary>

    - 회귀의 성능 측정
        
        [사진으로 대체]
        
    - 표기법
        
        [사진으로 대체]
        
        bold 글씨 : 벡터 / 일반 글씨 : 스칼라값
        
    
    **<코랩 코드 관련>**
    
    - info()
    - value_counts() : 특정 열에서 count
    - describe() : 각 특성의 수치를 요약해서 보여줌
    - train_test_spilt() - 사이킷런
        - permutation() : 배열을 섞어줌 → index로 사용 가능
        - iloc () : index 기반
        - loc () : 행의 순서대로 selecting
    - train set(70~80%) : 훈련 데이터 → 모델을 학습시키기 위한 데이터 → 입력(input)과 정답(label)을 바탕으로, 모델은 패턴을 찾아내고, 내부 가중치 조절
    - test set(20~30%) : 테스트 데이터 → 학습이 끝난 후, 모델이 얼마나 잘 일반화 되어 있는지 평가하기 위해 사용하는 새로운 데이터 → 모델이 한번도 본 적 없는 데이터 사용
    
    - hash 함수 : 임의의 크기를 가진 데이터를 고정된 크기의 값으로 변환하는 함수
        - 입력 → 고정된 출력 : 어떤 크기의 입력이든 항상 같은 길이의 출력값 생성
        - 결정적 함수 : 같은 입력값 → 항상 같은 해시값
        - 빠른 계산 : 계산 속도가 매우 빠름 (O(1)에 가까움)
        - 충돌 최소화 : 서로 다른 입력이 같은 해시값을 갖는 ‘충돌’ 발생 확률이 낮아야 함
    
    - StratifiedShuffleSplit
        - Stratified : 계층형 분할, 범주형 특성을 고르게 분할
            - stratify: 계층적으로 샘플링할 때 범주형 특성의 비율을 유지하면서 샘플링 할 수 있는 매개변수
        - compare_props
            - (preProps, nextProps) : 이전 prop, 다음 prop 비교 → 재렌더링 여부
            - (obj1, obj2) : 객체 속성 비교
            - (group1, group2) : 두 그래프 속성 차이 비교
    
    - cmap = plt.get_cmap(”jet”) : 값이 크면 red로, 값이 작으면 blue로
    - corr() : 행렬간 상관관계
    - SimpleImputer : 결측값을 평균, 중앙값 등으로 채워주는 전처리 도구
        - fit() : 평균, 중앙값 등 통계값을 계산 (실제로 바꿔주는건 아님)
        - statistics_ : fit() 이후 자동 생성 → 배열 형태로 저장
        - strategy : 어떤 방식으로 결측값 채울지 지정하는 전략 선택 옵션
    - 사이킷런
        - ordinalEncoder : 문자형 → 정수형
        - oneHotEncoder : 각각 하나씩 특징을 가짐
            - 하나만 1 나머지는 0
            - 기본적으로 희소행렬 반환 -toarray()→ 밀집배열 반환
            - sparse=False 적으면 바로 밀집배열 반환
    
    - 수치형 특성 전처리 pipeline
        - StandardScaler : 데이터에서 그 열의 평균을 빼고, 그 열의 표준 편차로 나눠서 표준 점수로 바꾸는 전처리 방법
        - oldDataFrameSelector : dataframe에서 각 열을 따로 따로 선택해주는 변환기
    
    - predict() : 예측값 구하기
    - mean_squared_error
    - mean_absolute_error - 1에 가까울 수록 좋음, 0에 가까울 수록 평균에 가까움
    - cross validation(교차 검증) - 여러번 반복 수행
        - cross_val_score
    
    - RandomForestRegressor
        - GridSearchCV
            - n_estimators : 결정트리 갯수
            - max_features : 랜덤하게 뽑아서 max값을..
            - bootstrap : false (3 - 25분..)
            - best_paramas
            - best_estimator
        - RandomizedSearchCV
            - n_estimators
            - max_features
    
    - 테스트 RMSE에 대한 95% 신뢰 구간 계산
        
        ```python
        from scipy import stats
        
        confidence = 0.95
        squared_errors = (final_predictions - y_test) ** 2
        np.sqrt(stats.t.interval(confidence, len(squared_errors) - 1,
                                 loc=squared_errors.mean(),
                                 scale=stats.sem(squared_errors)))
        ```
        
    - 추가
        - 전처리 + 예측 파이프라인
        - joblib 이용 - 객체를 저장해서 dump 메서드 사용해서 피클파일로 저장 가능 → 파이선 객체로 다시 저장
        - RandomizedSearchCV : geom(기하분포), expon(지수분포)
    
    - 요약
        1. 문제 정의 및 목표 설정
            - 비즈니스 목적 파악 (예: 캘리포니아 주택 가격 예측)
            - 지도학습 회귀 문제로 정의
        2. 데이터 수집
            - `fetch_california_housing()` 등으로 실제 데이터 획득
        3. 탐색적 데이터 분석 (EDA)
            - 히스토그램, 상관계수, 지리적 시각화 등
            - 데이터 분포, 이상치, 결측치 파악
        4. 데이터 전처리
            - 학습용/테스트용 분리 (`train_test_split`, `StratifiedShuffleSplit`)
            - 결측값 처리 (`SimpleImputer`)
            - 범주형 변수 변환 (`OneHotEncoder`)
            - 특성 스케일링 (`StandardScaler`)
        5. 특성 엔지니어링
            - 조합 특성 생성 (예: `rooms_per_household`)
            - 파이프라인 구축 (`Pipeline`, `ColumnTransformer`)
        6. 모델 선택 및 훈련
            - 선형 회귀, 결정 트리, 랜덤 포레스트 등 다양한 모델 훈련
            - 교차검증 (`cross_val_score`)으로 성능 비교
        7. 모델 튜닝
            - 그리드 서치 (`GridSearchCV`)와 랜덤 서치로 하이퍼파라미터 최적화
            - 최적 모델 선택
        8. 최종 평가
            - 테스트 세트로 최종 모델 평가
            - 회귀 성능지표(MAE, MSE, RMSE 등) 분석
        9. 모델 저장 및 재사용
            - `joblib` 등으로 모델 저장
            - 배포 및 재사용 고려

</details>
